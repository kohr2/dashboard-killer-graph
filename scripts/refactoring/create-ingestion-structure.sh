#!/bin/bash

# Script de crÃ©ation de la structure d'ingestion unifiÃ©e
# Transforme le "bordel" actuel en architecture propre

set -e

echo "ðŸ—ï¸ Creating Unified Data Ingestion Architecture..."
echo "=================================================="

# Couleurs pour les messages
GREEN='\033[0;32m'
BLUE='\033[0;34m'
YELLOW='\033[1;33m'
NC='\033[0m' # No Color

# CrÃ©er la structure principale
echo -e "${BLUE}ðŸ“ Creating main ingestion structure...${NC}"
mkdir -p src/ingestion/{core,sources,intelligence,api,config}

# CrÃ©er la structure core
echo -e "${BLUE}ðŸŽ¯ Creating core components...${NC}"
mkdir -p src/ingestion/core/{pipeline,adapters,processors,storage,types}

# CrÃ©er la structure sources
echo -e "${BLUE}ðŸ“¥ Creating data sources structure...${NC}"
mkdir -p src/ingestion/sources/{email,documents,apis,databases}
mkdir -p src/ingestion/sources/email/{providers,parsers,processors}
mkdir -p src/ingestion/sources/documents/{parsers,processors}
mkdir -p src/ingestion/sources/apis/{crm,financial,social}

# CrÃ©er la structure intelligence
echo -e "${BLUE}ðŸ§  Creating intelligence components...${NC}"
mkdir -p src/ingestion/intelligence/{nlp,ml,business}

# CrÃ©er la structure API
echo -e "${BLUE}ðŸŒ Creating API structure...${NC}"
mkdir -p src/ingestion/api/{controllers,middleware,validators}

# CrÃ©er la structure config
echo -e "${BLUE}âš™ï¸ Creating configuration structure...${NC}"
mkdir -p src/ingestion/config/{sources,pipelines,intelligence}

# CrÃ©er la structure de tests
echo -e "${BLUE}ðŸ§ª Creating test structure...${NC}"
mkdir -p test/ingestion/{unit,integration,e2e}
mkdir -p test/ingestion/unit/{core,sources,intelligence}
mkdir -p test/ingestion/integration/{pipelines,sources}

# CrÃ©er les fichiers de base avec des interfaces
echo -e "${BLUE}ðŸ“„ Creating base interface files...${NC}"

# Interface DataSource
cat > src/ingestion/core/types/data-source.interface.ts << 'EOF'
/**
 * Interface commune pour toutes les sources de donnÃ©es
 * Permet l'unification des diffÃ©rents types de sources
 */
export interface DataSource<T = any> {
  readonly id: string;
  readonly type: SourceType;
  readonly config: SourceConfig;
  
  connect(): Promise<void>;
  fetch(params?: FetchParams): AsyncIterable<T>;
  disconnect(): Promise<void>;
  healthCheck(): Promise<HealthStatus>;
}

export enum SourceType {
  EMAIL = 'email',
  DOCUMENT = 'document',
  API = 'api',
  DATABASE = 'database'
}

export interface SourceConfig {
  name: string;
  enabled: boolean;
  batchSize?: number;
  retryAttempts?: number;
  timeout?: number;
  [key: string]: any;
}

export interface FetchParams {
  limit?: number;
  offset?: number;
  filters?: Record<string, any>;
  dateRange?: {
    from: Date;
    to: Date;
  };
}

export interface HealthStatus {
  status: 'healthy' | 'degraded' | 'unhealthy';
  lastCheck: Date;
  message?: string;
  metrics?: Record<string, number>;
}
EOF

# Interface Pipeline
cat > src/ingestion/core/types/pipeline.interface.ts << 'EOF'
/**
 * Interface pour les pipelines d'ingestion
 * DÃ©finit le contrat pour le traitement unifiÃ© des donnÃ©es
 */
export interface IngestionPipeline {
  readonly id: string;
  readonly type: string;
  
  process(source: DataSource): Promise<ProcessingResult>;
  monitor(): PipelineMetrics;
  stop(): Promise<void>;
}

export interface ProcessingResult {
  success: boolean;
  sourceId: string;
  itemsProcessed: number;
  itemsSucceeded: number;
  itemsFailed: number;
  entitiesCreated: number;
  relationshipsCreated: number;
  duration: number;
  errors: ProcessingError[];
  metadata: Record<string, any>;
}

export interface PipelineMetrics {
  totalProcessed: number;
  averageProcessingTime: number;
  successRate: number;
  lastRun: Date;
  status: 'running' | 'idle' | 'error';
}

export interface ProcessingError {
  item: string;
  error: string;
  timestamp: Date;
  recoverable: boolean;
}
EOF

# Interface pour les donnÃ©es normalisÃ©es
cat > src/ingestion/core/types/normalized-data.interface.ts << 'EOF'
/**
 * Structure de donnÃ©es normalisÃ©e commune
 * Toutes les sources sont converties vers ce format
 */
export interface NormalizedData {
  id: string;
  sourceType: SourceType;
  sourceId: string;
  content: {
    title?: string;
    body: string;
    summary?: string;
    language?: string;
  };
  metadata: {
    timestamp: Date;
    author?: string;
    recipients?: string[];
    tags?: string[];
    classification?: string;
    confidence?: number;
    [key: string]: any;
  };
  raw: any; // DonnÃ©es originales pour rÃ©fÃ©rence
}
EOF

# CrÃ©er le fichier index principal
cat > src/ingestion/index.ts << 'EOF'
/**
 * Point d'entrÃ©e principal pour la plateforme d'ingestion unifiÃ©e
 */

// Core types
export * from './core/types/data-source.interface';
export * from './core/types/pipeline.interface';
export * from './core/types/normalized-data.interface';

// Core components (Ã  implÃ©menter)
// export * from './core/pipeline/ingestion-pipeline';
// export * from './core/adapters/base-adapter';

// Sources (Ã  implÃ©menter)
// export * from './sources/email/email-source';
// export * from './sources/documents/document-source';

// Intelligence (Ã  implÃ©menter)
// export * from './intelligence/nlp/entity-extractor';

// API (Ã  implÃ©menter)
// export * from './api/controllers/ingestion.controller';
EOF

# CrÃ©er un README pour la nouvelle architecture
cat > src/ingestion/README.md << 'EOF'
# ðŸ“Š Unified Data Ingestion Platform

Cette plateforme d'ingestion unifiÃ©e remplace l'ancienne architecture dispersÃ©e et fournit un point d'entrÃ©e unique pour toutes les sources de donnÃ©es.

## ðŸ—ï¸ Architecture

```
src/ingestion/
â”œâ”€â”€ core/           # Composants centraux
â”‚   â”œâ”€â”€ pipeline/  # Traitement unifiÃ©
â”‚   â”œâ”€â”€ adapters/  # Adaptateurs sources
â”‚   â””â”€â”€ types/     # Interfaces communes
â”œâ”€â”€ sources/        # Sources spÃ©cialisÃ©es
â”‚   â”œâ”€â”€ email/     # Emails (IMAP, .eml, etc.)
â”‚   â”œâ”€â”€ documents/ # PDFs, Word, etc.
â”‚   â””â”€â”€ apis/      # APIs externes
â”œâ”€â”€ intelligence/   # IA centralisÃ©e
â”‚   â”œâ”€â”€ nlp/       # NLP unifiÃ©
â”‚   â”œâ”€â”€ ml/        # Machine Learning
â”‚   â””â”€â”€ business/  # Intelligence mÃ©tier
â””â”€â”€ api/            # APIs REST
    â””â”€â”€ controllers/ # Points d'entrÃ©e
```

## ðŸš€ Utilisation

```typescript
// Exemple d'ingestion d'emails
const emailSource = new EmailSource(new EmlProvider('./emails'));
const pipeline = new IngestionPipeline(config);

const result = await pipeline.process(emailSource);
console.log(`Processed ${result.itemsProcessed} items`);
```

## ðŸŽ¯ Avantages

- âœ… **Unification** : Un seul pipeline pour toutes les sources
- âœ… **ExtensibilitÃ©** : Ajout facile de nouvelles sources
- âœ… **MaintenabilitÃ©** : Architecture modulaire et testable
- âœ… **Performance** : Traitement optimisÃ© par lots
- âœ… **Monitoring** : MÃ©triques et observabilitÃ© intÃ©grÃ©es

## ðŸ“‹ Migration

Cette architecture remplace :
- `src/ontologies/crm/application/services/email-*.ts`
- `src/platform/processing/content-processing.service.ts`
- `scripts/demo-email-ingestion-spacy.ts`

Voir `docs/architecture/refactoring-plan.md` pour le plan de migration complet.
EOF

# CrÃ©er les fichiers .gitkeep pour prÃ©server la structure
find src/ingestion -type d -empty -exec touch {}/.gitkeep \;
find test/ingestion -type d -empty -exec touch {}/.gitkeep \;

echo ""
echo -e "${GREEN}âœ… Unified ingestion structure created successfully!${NC}"
echo ""
echo -e "${YELLOW}ðŸ“ Structure created:${NC}"
echo "   ðŸ“Š src/ingestion/ - Main ingestion platform"
echo "   ðŸŽ¯ src/ingestion/core/ - Core components"
echo "   ðŸ“¥ src/ingestion/sources/ - Data sources"
echo "   ðŸ§  src/ingestion/intelligence/ - AI components"
echo "   ðŸŒ src/ingestion/api/ - REST APIs"
echo "   âš™ï¸ src/ingestion/config/ - Configuration"
echo "   ðŸ§ª test/ingestion/ - Unified tests"
echo ""
echo -e "${YELLOW}ðŸ“„ Files created:${NC}"
echo "   ðŸ“‹ Base interfaces and types"
echo "   ðŸ“– Documentation and README"
echo "   ðŸ”§ Index file for exports"
echo ""
echo -e "${BLUE}ðŸš€ Next steps:${NC}"
echo "   1. Review the created structure"
echo "   2. Run: ./scripts/refactoring/migrate-email-services.sh"
echo "   3. Implement the core pipeline components"
echo "   4. Migrate existing email services"
echo ""
echo "ðŸŽ¯ This structure will replace the current scattered email processing!" 